{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper2issn(use_all=False):\n",
    "    read_path = '../data/stat_paper.csv'\n",
    "    write_path = '../data/paper2issn.json'\n",
    "    if use_all:\n",
    "        read_path = '../data/paper_info_1990.csv'\n",
    "        write_path = '../data/paper2issn_all.json'\n",
    "    stat_paper = pd.read_csv(read_path)\n",
    "    paper_id, issn = stat_paper['id'].tolist(), stat_paper['issn'].tolist()\n",
    "    paper2issn = {}\n",
    "    for pid, pissn in zip(paper_id, issn):\n",
    "        paper2issn[pid] = pissn\n",
    "    json.dump(paper2issn, open(write_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_paper2issn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_idx(column, save_path):\n",
    "    mapping = {}\n",
    "    array = column.tolist()\n",
    "    for id in array:\n",
    "        if id not in mapping:\n",
    "            mapping[id] = len(mapping) + 1\n",
    "    with open(save_path, 'w') as f:\n",
    "        json.dump(mapping, f)\n",
    "    print('Data saved at', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved at ../data/paper2idx.json\n",
      "Data saved at ../data/journal2idx.json\n"
     ]
    }
   ],
   "source": [
    "stat_paper_50 = pd.read_csv('../data/stat_paper_50.csv')\n",
    "create_idx(stat_paper_50['id'], '../data/paper2idx.json')\n",
    "create_idx(stat_paper_50['issn'], '../data/journal2idx.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved at ../data/journal2idx_all.json\n"
     ]
    }
   ],
   "source": [
    "all_paper = pd.read_csv('../data/paper_info_1990.csv')\n",
    "create_idx(all_paper['issn'], '../data/journal2idx_all.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper2abstract():\n",
    "    abstract = pd.read_csv('../data/paper_abstract.csv')\n",
    "    paper2abstract = {}\n",
    "    paper_ids, paper_abstract = abstract['id'].tolist(), abstract['abstract'].tolist()\n",
    "    for id, ab in zip(paper_ids, paper_abstract):\n",
    "        paper2abstract[id] = ab\n",
    "    return paper2abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper2abstract = get_paper2abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper2rank5():\n",
    "    df = pd.read_csv('../data/stat_paper_50.csv')\n",
    "    paper2rank5 = {}\n",
    "    paper_ids, rank5 = df['id'].tolist(), df['rank5'].tolist()\n",
    "    for id, rank in zip(paper_ids, rank5):\n",
    "        paper2rank5[id] = rank\n",
    "    with open('../data/paper2rank5.json', 'w') as f:\n",
    "        json.dump(paper2rank5, f)\n",
    "    print('Paper2rank5 saved at ../data/paper2rank5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper2rank5 saved at ../data/paper2rank5.json\n"
     ]
    }
   ],
   "source": [
    "get_paper2rank5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_abstract_dataset(paper2idx_path, journal2idx_path, paper2issn_path, paper2abstract):\n",
    "    paper2idx = json.load(open(paper2idx_path, 'r'))\n",
    "    journal2idx = json.load(open(journal2idx_path, 'r'))\n",
    "    paper2issn = json.load(open(paper2issn_path, 'r'))\n",
    "    paper2rank5 = json.load(open('../data/paper2rank5.json', 'r'))\n",
    "    \n",
    "    dataset = []\n",
    "    for paper_id, _ in paper2idx.items():\n",
    "        dataset.append({'paper_id': paper_id, \n",
    "                        'abstract':paper2abstract[paper_id], \n",
    "                        'journal_id':journal2idx[paper2issn[paper_id]],\n",
    "                        'rank5':paper2rank5[paper_id]})\n",
    "    json.dump(dataset, open('../data/dataset_stat_50.json', 'w'))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_abstract_dataset('../data/paper2idx.json', \n",
    "                         '../data/journal2idx.json', \n",
    "                         '../data/paper2issn.json',\n",
    "                         paper2abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7953 12835 14996 ...  4182   957  6830]\n"
     ]
    }
   ],
   "source": [
    "permuted_idx = np.random.permutation(np.arange(len(dataset)))\n",
    "print(permuted_idx)\n",
    "with open('../data/permuted_idx.json', 'w') as f:\n",
    "    json.dump(permuted_idx.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(dataset, \n",
    "                         save_path,\n",
    "                         feature_col_list, \n",
    "                         train_ratio=0.8, \n",
    "                         val_ratio=0.1, \n",
    "                         test_ratio=0.1):\n",
    "    dataset = np.asarray(dataset)\n",
    "    permuted_idx = json.load(open('../data/permuted_idx.json', 'r'))\n",
    "    total_n = dataset.shape[0]\n",
    "    dataset = dataset[permuted_idx]\n",
    "    test_idx = int(total_n * test_ratio)\n",
    "    val_idx = int(total_n * (test_ratio + val_ratio))\n",
    "    train, val, test = dataset[:-val_idx], dataset[-val_idx:-test_idx], dataset[-test_idx:]\n",
    "    \n",
    "    train, val, test = train.tolist(), val.tolist(), test.tolist()\n",
    "    splitted_data = {}\n",
    "    \n",
    "    for phase, subset in zip(['train', 'val', 'test'], [train, val, test]):\n",
    "        for feature_col in feature_col_list:\n",
    "            name = 'X_{}_{}'.format(phase, feature_col)\n",
    "            feature = [data[feature_col] for data in subset]\n",
    "            splitted_data[name] = feature\n",
    "        name_journal = 'y_{}_journal'.format(phase)\n",
    "        name_rank = 'y_{}_rank'.format(phase)\n",
    "\n",
    "        y_journal = [data['journal_id'] for data in subset]\n",
    "        y_rank = [data['rank5'] for data in subset]\n",
    "\n",
    "        splitted_data[name_journal] = y_journal\n",
    "        splitted_data[name_rank] = y_rank\n",
    "            \n",
    "    print(list(splitted_data.keys()))\n",
    "#     X_train = [data[feature_col] for data in train]\n",
    "#     y_train = [data['journal_id'] for data in train]\n",
    "#     X_val = [data[feature_col] for data in val]\n",
    "#     y_val = [data['journal_id'] for data in val]\n",
    "#     X_test = [data[feature_col] for data in test]\n",
    "#     y_test = [data['journal_id'] for data in test]\n",
    "    \n",
    "#     splitted_data = {'X_train': X_train, 'y_train': y_train,\n",
    "#                     'X_val': X_val, 'y_val': y_val,\n",
    "#                     'X_test': X_test, 'y_test': y_test}\n",
    "    np.save(save_path, splitted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train_abstract', 'y_train_journal', 'y_train_rank', 'X_val_abstract', 'y_val_journal', 'y_val_rank', 'X_test_abstract', 'y_test_journal', 'y_test_rank']\n"
     ]
    }
   ],
   "source": [
    "# split abstract dataset\n",
    "train_val_test_split(dataset, '../data/dataset_abstract_stat_50', feature_col_list=['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper2chain():\n",
    "    reference = pd.read_csv('../data/stat_paper_50_ref_chain.csv')\n",
    "    paper2reference = {}\n",
    "    paper_ids, paper_reference = reference['id'].tolist(), reference['ref_chain'].tolist()\n",
    "    for id, ref in zip(paper_ids, paper_reference):\n",
    "        paper2reference[id] = json.loads(ref.replace(\"'\", \"\\\"\"))\n",
    "    return paper2reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper2chain = get_paper2chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper2neighbor():\n",
    "    df = pd.read_csv('../data/stat_paper_50_neighbors.csv')\n",
    "    paper2nb = {}\n",
    "    ids = df['id'].tolist()\n",
    "    neighbors = df['neighbors'].tolist()\n",
    "    \n",
    "    for id, ref in zip(ids, neighbors):\n",
    "        level1 = []\n",
    "        level2 = []\n",
    "        adjusted_ref = ref.replace(\"'\", \"\\\"\")\n",
    "        adjusted_ref = adjusted_ref.replace(\"(\", \"[\")\n",
    "        adjusted_ref = adjusted_ref.replace(\")\", \"]\")\n",
    "        nbs = json.loads(adjusted_ref)\n",
    "        for item in nbs:\n",
    "            level1.append(item[0])\n",
    "            level2.extend(list(item[1]))\n",
    "        paper2nb[id] = (level1, level2)\n",
    "    return paper2nb\n",
    "    \n",
    "paper2neighbor = get_paper2neighbor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_chain_dataset(save_path,\n",
    "                            paper2idx_path, \n",
    "                             journal2idx_path, \n",
    "                             paper2issn_path, \n",
    "                             paper2reference):\n",
    "    \n",
    "    paper2idx = json.load(open(paper2idx_path, 'r'))\n",
    "    journal2idx = json.load(open(journal2idx_path, 'r'))\n",
    "    label2idx = json.load(open('../data/journal2idx.json', 'r'))\n",
    "    paper2issn = json.load(open(paper2issn_path, 'r'))\n",
    "    paper2rank5 = json.load(open('../data/paper2rank5.json', 'r'))\n",
    "    dataset = []\n",
    "    \n",
    "    for paper_id, _ in paper2idx.items():\n",
    "        ref_chain = []\n",
    "        for sublist in paper2reference[paper_id]:\n",
    "            for idx, item in enumerate(sublist):\n",
    "                if idx > 0 and item in paper2issn:\n",
    "                    ref_chain.append(journal2idx[paper2issn[item]])\n",
    "        \n",
    "        dataset.append({'paper_id': paper_id, \n",
    "                        'ref_chain': ref_chain, \n",
    "                        'journal_id':label2idx[paper2issn[paper_id]],\n",
    "                        'rank5': paper2rank5[paper_id]})\n",
    "    json.dump(dataset, open(save_path, 'w'))\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paper2chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a4645e24685b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                          \u001b[0;34m'../data/journal2idx_all.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0;34m'../data/paper2issn_all.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                          paper2chain)\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'paper2chain' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = create_reference_chain_dataset('../data/dataset_stat_50_ref.json',\n",
    "                        '../data/paper2idx.json', \n",
    "                         '../data/journal2idx_all.json', \n",
    "                         '../data/paper2issn_all.json',\n",
    "                         paper2chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train_ref_chain', 'y_train_journal', 'y_train_rank', 'X_val_ref_chain', 'y_val_journal', 'y_val_rank', 'X_test_ref_chain', 'y_test_journal', 'y_test_rank']\n"
     ]
    }
   ],
   "source": [
    "train_val_test_split(dataset, '../data/dataset_ref_chain_stat_50', feature_col_list=['ref_chain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_neighbor_dataset(save_path,\n",
    "                            paper2idx_path, \n",
    "                             journal2idx_path, \n",
    "                             paper2issn_path, \n",
    "                             paper2reference):\n",
    "    \n",
    "    paper2idx = json.load(open(paper2idx_path, 'r'))\n",
    "    journal2idx = json.load(open(journal2idx_path, 'r'))\n",
    "    label2idx = json.load(open('../data/journal2idx.json', 'r'))\n",
    "    paper2issn = json.load(open(paper2issn_path, 'r'))\n",
    "    paper2rank5 = json.load(open('../data/paper2rank5.json', 'r'))\n",
    "    dataset = []\n",
    "    for paper_id, _ in paper2idx.items():\n",
    "        level1, level2 = paper2reference[paper_id][0], paper2reference[paper_id][1]\n",
    "        issn1 = []\n",
    "        issn2 = []\n",
    "        for item in level1:\n",
    "            if item == '_PAD_':\n",
    "                issn1.append(0)\n",
    "            else:\n",
    "                try:\n",
    "                    issn1.append(journal2idx[paper2issn[item]])\n",
    "                except:\n",
    "                    print(paper2issn[item])\n",
    "                    issn1.append(0)\n",
    "        for item in level2:\n",
    "            if item == '_PAD_':\n",
    "                issn2.append(0)\n",
    "            else:\n",
    "                try:\n",
    "                    issn2.append(journal2idx[paper2issn[item]])\n",
    "                except:\n",
    "                    print(paper2issn[item])\n",
    "                    issn2.append(0)\n",
    "        \n",
    "        dataset.append({'paper_id': paper_id, \n",
    "                        'ref_level1': issn1, \n",
    "                        'ref_level2': issn2,\n",
    "                        'journal_id':label2idx[paper2issn[paper_id]],\n",
    "                        'rank5': paper2rank5[paper_id]})\n",
    "    json.dump(dataset, open(save_path, 'w'))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_reference_neighbor_dataset('../data/dataset_stat_50_ref.json',\n",
    "                        '../data/paper2idx.json', \n",
    "                         '../data/journal2idx_all.json', \n",
    "                         '../data/paper2issn_all.json',\n",
    "                         paper2neighbor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train_ref_level1', 'X_train_ref_level2', 'y_train_journal', 'y_train_rank', 'X_val_ref_level1', 'X_val_ref_level2', 'y_val_journal', 'y_val_rank', 'X_test_ref_level1', 'X_test_ref_level2', 'y_test_journal', 'y_test_rank']\n"
     ]
    }
   ],
   "source": [
    "train_val_test_split(dataset, '../data/dataset_ref_nb_stat_50', feature_col_list=['ref_level1', 'ref_level2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
